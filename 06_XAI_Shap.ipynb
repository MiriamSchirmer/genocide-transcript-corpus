{"cells":[{"cell_type":"markdown","metadata":{"id":"JJ5Y5CaqwAAg"},"source":["### Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"unC1hjUtxa-A"},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2\n","\n","#########################################################################################\n","#########################################################################################\n","####### BEGIN OPTIONAL SECTION\n","#########################################################################################\n","#########################################################################################\n","GLB_INSTALL_DEPENDENCIES = True\n","\n","# Here to define dependencies\n","if GLB_INSTALL_DEPENDENCIES:\n","    !pip install transformers\n","    !pip install captum\n","    !pip install shap \n","#########################################################################################\n","#########################################################################################\n","####### END OPTIONAL SECTION\n","#########################################################################################\n","#########################################################################################"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j3GCxXtTv5iV"},"outputs":[],"source":["import matplotlib\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from scipy import stats\n","import pandas as pd\n","import os\n","from os.path import join\n","import numpy as np\n","\n","import torch\n","\n","from transformers import BertForSequenceClassification, BertTokenizerFast#,  BertTokenizer\n","from transformers import AutoModelForSequenceClassification #AutoTokenizer\n","from transformers import BertTokenizer, BertConfig\n","\n","import src.classification_model_utilities as mlclassif_utilities\n","import src.general_utilities as gral_utilities\n","\n","from captum.attr import visualization as viz\n","from captum.attr import IntegratedGradients, LayerConductance, LayerIntegratedGradients\n","from captum.attr import configure_interpretable_embedding_layer, remove_interpretable_embedding_layer\n","\n","import scipy as sp\n","import shap"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZlufhZIpxAg7"},"outputs":[],"source":["model_id = \"bert\"\n","\n","path_model = #\"\" Write path to the model\n","\n","model_name = \"bert-base-uncased\"\n","#model_name = \"GroNLP/hateBERT\"\n","\n","_num_classes = 2\n","_output_attentions = True\n","_output_hidden_states = True"]},{"cell_type":"markdown","metadata":{"id":"MnPUVIMmUll2"},"source":["## Read Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qYnhYc9gUnhg"},"outputs":[],"source":["global_config_file = gral_utilities.read_config_file(\"config.yml\")\n","\n","PATH_DATASET = global_config_file[\"general_set_up\"][\"dataset_filename\"]\n","PATH_DIR_INPUT = global_config_file[\"general_set_up\"][\"input_dir_name\"]\n","PATH_DIR_DATASET = global_config_file[\"general_set_up\"][\"dataset_dir_name\"]\n","INDEX_COLUMNS_DATASET = global_config_file[\"dataset\"][\"index_columns_dataset\"] # 1\n","LIST_NAME_COLUMNS_DATASET = global_config_file[\"dataset\"][\"list_columns_names\"]\n","\n","df_dataset = mlclassif_utilities.import_dataset_from_excel(join(PATH_DIR_INPUT, PATH_DIR_DATASET, PATH_DATASET), INDEX_COLUMNS_DATASET, LIST_NAME_COLUMNS_DATASET)\n","df_dataset.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YoPIelnyVqku"},"outputs":[],"source":["list_sentences = df_dataset[\"text\"]\n","list_sentences"]},{"cell_type":"markdown","metadata":{"id":"6ls0HVBvTYHg"},"source":["## Load Model & tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"94EVt30sTaJl"},"outputs":[],"source":["tokenizer = mlclassif_utilities.get_tokenizer(model_id, model_name) \n","device = mlclassif_utilities.get_gpu_device_if_exists()\n","\n","model = torch.load(path_model)\n","model.to(device)\n","model.eval()\n","model.zero_grad()"]},{"cell_type":"markdown","metadata":{"id":"IA5aelRDW505"},"source":["# Shap"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NsbypmBeW81C"},"outputs":[],"source":["#tokenizer = BertTokenizerFast.from_pretrained(model_name, do_lower_case=False)\n","\n","def f(x):\n","    tv = torch.tensor([tokenizer.encode(v, padding='max_length', max_length=512, truncation=True) for v in x]).cuda()\n","    outputs = model(tv)[0].detach().cpu().numpy()\n","    #print(outputs)\n","    scores = (np.exp(outputs).T / np.exp(outputs).sum(-1)).T\n","    val = sp.special.logit(scores[:,1]) # use one vs rest logit units\n","    return val"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7ONPVqxoXROu"},"outputs":[],"source":["explainer = shap.Explainer(f, tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-kHsewVTfMxn"},"outputs":[],"source":["shap_values = explainer(list_sentences, fixed_context=1, batch_size=2)\n","#shap_values = explainer(list_sentences[0:50], fixed_context=1, batch_size=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"30UNGnCeZFwb"},"outputs":[],"source":["shap.plots.text(shap_values[:100], display=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BgJOk3mhvULW"},"outputs":[],"source":["resultado_plots = shap.plots.text(shap_values[:100], display=False)"]},{"cell_type":"markdown","metadata":{"id":"t0LVVlDI_vrm"},"source":["### Other visualizations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wBme0EAFATRT"},"outputs":[],"source":["shap.plots.bar(shap_values)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xX2S8QXMAW1k"},"outputs":[],"source":["shap.plots.waterfall(shap_values[0])"]},{"cell_type":"markdown","metadata":{"id":"tUSfZnNjseeK"},"source":["# Missclassifications"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bFlN4hyCWSty"},"outputs":[],"source":["import random"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aBuFL6ejAnfn"},"outputs":[],"source":["ground_truth = df_dataset[df_dataset[\"role\"]==\"Witness\"][\"trauma\"]\n","list_sentences = df_dataset[df_dataset[\"role\"]==\"Witness\"][\"text\"]\n","\n","seed_val = 42\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","\n","all_spans_tokenized = mlclassif_utilities.get_all_spans_tokenized(\n","        tokenizer,\n","        list_sentences,\n","        _add_special_tokens = False, \n","        _max_length = 512,\n","        _pad_to_max_length = True,\n","        _return_attention_mask = True, \n","        type_tensors = \"pt\"\n","    )\n","\n","input_ids = mlclassif_utilities.convert_list_into_pytorch_tensor(all_spans_tokenized[0])\n","attention_masks = mlclassif_utilities.convert_list_into_pytorch_tensor(all_spans_tokenized[1])\n","numeric_classes = mlclassif_utilities.convert_list_labels_into_pytorch_tensor(list(ground_truth))\n","\n","input_ids = input_ids.to(device)\n","attention_masks = attention_masks.to(device)\n","numeric_classes = numeric_classes.to(device)\n","\n","dataset = mlclassif_utilities.create_tensor_dataset(input_ids, attention_masks, numeric_classes)\n","dataloader = mlclassif_utilities.create_dataloader(dataset, 32)\n","\n","def predict(model, device, dataloader):\n","    predictions = list()\n","    model.eval()\n","\n","    for batch in dataloader:\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        with torch.no_grad():\n","            result = model(b_input_ids, \n","                          token_type_ids=None, \n","                          attention_mask=b_input_mask,\n","                          labels=b_labels,\n","                          return_dict=True)\n","        loss = result.loss\n","        logits = result.logits\n","\n","        predictions.extend(logits.argmax(dim=1).cpu().numpy())\n","    return predictions\n","\n","predictions = predict(model, device, dataloader)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"71qCe3mrsnST","executionInfo":{"status":"ok","timestamp":1676083005712,"user_tz":-60,"elapsed":19,"user":{"displayName":"Isaac Olgu√≠n","userId":"09697151780329788960"}},"outputId":"f5657e36-98ca-4c33-9fc5-2cd3577ea63e"},"outputs":[{"output_type":"stream","name":"stdout","text":["6132\n"]}],"source":["list_indices = list()\n","list_ground_truth = list()\n","list_predictions = list()\n","list_text_sentences = list()\n","list_sentences_2 = list(list_sentences)\n","for index, (true, prediction) in enumerate(zip(ground_truth, predictions)):\n","  if true != prediction:\n","    list_ground_truth.append(true)\n","    list_predictions.append(prediction)\n","    list_text_sentences.append(list_sentences_2[index])\n","    list_indices.append(index)\n","\n","print(len(list_indices))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OvmWn4qysstK"},"outputs":[],"source":["json_info = {\"ground_truth\": list_ground_truth, \"predictions\": list_predictions, \"text\": list_text_sentences}\n","df_info = pd.DataFrame.from_dict(json_info).reset_index()\n","#df_info.to_excel(\"Misclassifications_[writeSpecPattern].xlsx\")"]},{"cell_type":"code","source":[],"metadata":{"id":"URS7mrwgVeFc"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyPUdwzLp8EITNd6xfyGvuid"},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}